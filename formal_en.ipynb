{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09331806",
   "metadata": {},
   "source": [
    "# Term frequency of formal english corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e26233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import reuters\n",
    "from nltk.corpus import gutenberg\n",
    "from typing import AnyStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded081d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\USER/nltk_data',\n",
       " 'S:\\\\dev\\\\seahrh\\\\nlp-examples\\\\env\\\\nltk_data',\n",
       " 'S:\\\\dev\\\\seahrh\\\\nlp-examples\\\\env\\\\share\\\\nltk_data',\n",
       " 'S:\\\\dev\\\\seahrh\\\\nlp-examples\\\\env\\\\lib\\\\nltk_data',\n",
       " 'C:\\\\Users\\\\USER\\\\AppData\\\\Roaming\\\\nltk_data',\n",
       " 'C:\\\\nltk_data',\n",
       " 'D:\\\\nltk_data',\n",
       " 'E:\\\\nltk_data']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('brown')\n",
    "nltk.download('reuters')\n",
    "nltk.download('gutenberg')\n",
    "nltk.data.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aee719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(bytes_or_str: AnyStr, encoding=\"utf-8\") -> str:\n",
    "    \"\"\"Based on Effective Python Item 3:\n",
    "    Know the difference between bytes str and unicode\n",
    "    \"\"\"\n",
    "    if isinstance(bytes_or_str, bytes):\n",
    "        return bytes_or_str.decode(encoding)\n",
    "    # Instance of str\n",
    "    return bytes_or_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b6e3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,651,012 words\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = [to_str(w).lower() for w in wn.words()]\n",
    "words += [to_str(w).lower() for w in brown.words()]\n",
    "words += [to_str(w).lower() for w in reuters.words()]\n",
    "words += [to_str(w).lower() for w in gutenberg.words()]\n",
    "print(f\"{len(words):,} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7772a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202,023 words\n",
      "Wall time: 2.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fd = nltk.FreqDist(words)\n",
    "print(f\"{len(fd):,} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c6425f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 316785),\n",
       " ('the', 272831),\n",
       " ('.', 217779),\n",
       " ('and', 149943),\n",
       " ('of', 144458),\n",
       " ('to', 110615),\n",
       " ('in', 84171),\n",
       " ('a', 82259),\n",
       " (':', 50900),\n",
       " ('that', 46932),\n",
       " ('for', 42798),\n",
       " ('it', 42168),\n",
       " (';', 41657),\n",
       " ('he', 40621),\n",
       " ('said', 36774),\n",
       " ('i', 36166),\n",
       " ('was', 34346),\n",
       " ('is', 34212),\n",
       " (\"'\", 31462),\n",
       " ('with', 31067),\n",
       " ('his', 29071),\n",
       " ('be', 28850),\n",
       " ('not', 26373),\n",
       " ('as', 26357),\n",
       " ('s', 25599),\n",
       " ('on', 24582),\n",
       " ('-', 22633),\n",
       " ('\"', 22238),\n",
       " ('but', 21927),\n",
       " ('from', 21663),\n",
       " ('at', 21564),\n",
       " ('by', 20920),\n",
       " ('you', 19873),\n",
       " ('they', 19319),\n",
       " ('mln', 18623),\n",
       " ('had', 18425),\n",
       " ('all', 18021),\n",
       " ('this', 17576),\n",
       " ('have', 17166),\n",
       " ('which', 16002),\n",
       " ('him', 15703),\n",
       " ('will', 15566),\n",
       " ('her', 14598),\n",
       " ('vs', 14529),\n",
       " ('are', 14464),\n",
       " ('or', 13780),\n",
       " ('1', 13397),\n",
       " ('were', 13247),\n",
       " ('an', 13195),\n",
       " ('one', 12474)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7454ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtf\t\t0.0\n",
      "omg\t\t0.0\n",
      "dog\t\t3.3976215233660804e-05\n"
     ]
    }
   ],
   "source": [
    "ws = [\"wtf\", \"omg\", \"dog\"]\n",
    "for w in ws:\n",
    "    print(f\"{w}\\t\\t{fd.freq(w)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca4458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/formal_en.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter='\\t', lineterminator='\\n')\n",
    "    writer.writerow([\"Word\", \"Count\"])\n",
    "    for word, count in fd.most_common():\n",
    "        writer.writerow([word, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4591eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
